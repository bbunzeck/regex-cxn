{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa40a0ae",
   "metadata": {},
   "source": [
    "# mor-annotation to construction types\n",
    "\n",
    "Intended functionality:\n",
    "- read dataframe with tidied CHILDES data\n",
    "- determine construction types on basis of morphological annotation (mor-tier)\n",
    "- add first one/two/three lemmas of every utterance for later analysis of lexical specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path, re\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6af782",
   "metadata": {},
   "source": [
    "# Load transcription df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e97377",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('manual-anno.csv', sep=\"\\t\", index_col=0, na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d4fb3",
   "metadata": {},
   "source": [
    "# Construction types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf93fb",
   "metadata": {},
   "source": [
    "[Cameron-Faulkner et al. (2003)](https://www.eva.mpg.de/documents/Wiley-Blackwell/Cameron-Faulkner_Construction_CogScience_2003_1555820.pdf) define the following construction categories:\n",
    "- fragments (utterances without subject and predicate)\n",
    "    - x(fow) one word \n",
    "    - x(fnp) noun phrase\n",
    "    - x(fvp) verb phrase\n",
    "    - x(fpp) prepositional phrase\n",
    "    - (fmw) other multi-word\n",
    "- questions\n",
    "    - x(qwh) wh-questions\n",
    "    - x(qyn) yes/no-questions\n",
    "- (imp) imperatives\n",
    "- x(cop) copula\n",
    "- subject-predicate\n",
    "    - x(spt) transitive\n",
    "    - (spi) intransitive\n",
    "    - (spo) other\n",
    "- x(com) complex (two lexical verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a75559",
   "metadata": {},
   "source": [
    "### Construction finder\n",
    "\n",
    "based on debugger and its sub-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cxn(mor_line, clean_line):\n",
    "    mor_line = mor_line.replace(\"adv|\",\"adve|\")\n",
    "    pos_line = mor_line.replace(\"~\",\" \")\n",
    "    pos_list = pos_line.split()\n",
    "    clean_pos_list = []\n",
    "    for element in pos_list:\n",
    "        head, sep, tail = element.partition('|')\n",
    "        clean_pos_list.append(head)\n",
    "    if match_frp(clean_line):\n",
    "        return(\"frp\")\n",
    "    elif match_ffi(clean_line):\n",
    "        return(\"ffi\")\n",
    "    elif match_fow(mor_line, clean_pos_list):\n",
    "        return(\"fow\")\n",
    "    #elif mor_line.count(\"?\") > 0:\n",
    "    elif mor_line[-1] == \"?\":\n",
    "        if match_qwh(mor_line, clean_pos_list):\n",
    "            return(\"qwh\")\n",
    "        else:\n",
    "            return(match_qyn(mor_line, clean_pos_list))\n",
    "    elif match_cop(mor_line, clean_pos_list):\n",
    "        return(\"cop\")\n",
    "    elif match_com2(mor_line, clean_pos_list):\n",
    "        return(\"com\")\n",
    "    elif match_spt(mor_line, clean_pos_list):\n",
    "        return(\"spt\")\n",
    "    elif match_spi(mor_line, clean_pos_list):\n",
    "        return(\"spi\")\n",
    "    elif match_imp(mor_line, clean_pos_list):\n",
    "        return(\"imp\")\n",
    "    elif match_fvp(mor_line, clean_pos_list):\n",
    "        return(\"fvp\")\n",
    "    elif match_fnp(mor_line, clean_pos_list):\n",
    "        return(\"fnp\")\n",
    "    elif match_fpp(mor_line, clean_pos_list):\n",
    "        return(\"fpp\")\n",
    "    elif match_fom(mor_line, clean_pos_list):\n",
    "        return(\"fom\")\n",
    "    else:\n",
    "        return(\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b875f65",
   "metadata": {},
   "source": [
    "### Construction debugger regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cxn_debug(mor_line, clean_line):\n",
    "    mor_line = mor_line.replace(\"adv|\",\"adve|\")\n",
    "    pos_line = mor_line.replace(\"~\",\" \")\n",
    "    pos_list = pos_line.split()\n",
    "    clean_pos_list = []\n",
    "    for element in pos_list:\n",
    "        head, sep, tail = element.partition('|')\n",
    "        clean_pos_list.append(head)\n",
    "    #print(clean_pos_list)\n",
    "    candidates = []\n",
    "    # look at all sentences ending in \"?\" --> question\n",
    "    # begins with interrogative pronoun (optional preposition) --> qwh\n",
    "    # begins with aux/mod/cop (optional ???) --> qyn\n",
    "    # is there a subject, no main verb, but a copula --> cop\n",
    "    # does the sentence begin with a main verb and has no subject in front? --> imp\n",
    "    # are there two or more lexical verbs with something subject-y? --> com\n",
    "    # is there one lexical verb with something subject-y? --> subject-predicate\n",
    "    # something object-like after the verb? --> spt\n",
    "    # nothing object-like after the verb? --> spi\n",
    "    # only one word --> fow\n",
    "    # something noun-y without predicate? --> fnp\n",
    "    # something verb-y without subject? --> fvp\n",
    "    # nothing verb-y and utterance begins with preposition --> fpp\n",
    "    # multi-word, but weird repetition etc. --> fom\n",
    "    # empty mor tier --> NA\n",
    "    candidates.append(match_frp(clean_line))\n",
    "    candidates.append(match_ffi(clean_line))\n",
    "    candidates.append(match_fow(mor_line, clean_pos_list))\n",
    "    candidates.append(match_fnp(mor_line, clean_pos_list))\n",
    "    candidates.append(match_fvp(mor_line, clean_pos_list))\n",
    "    candidates.append(match_fpp(mor_line, clean_pos_list))\n",
    "    candidates.append(match_fom(mor_line, clean_pos_list))\n",
    "    candidates.append(match_qwh(mor_line, clean_pos_list))\n",
    "    candidates.append(match_qyn(mor_line, clean_pos_list))\n",
    "    candidates.append(match_imp(mor_line, clean_pos_list))\n",
    "    candidates.append(match_cop(mor_line, clean_pos_list))\n",
    "    candidates.append(match_spt(mor_line, clean_pos_list))\n",
    "    candidates.append(match_spi(mor_line, clean_pos_list))\n",
    "    candidates.append(match_spo(mor_line, clean_pos_list))\n",
    "    candidates.append(match_com(mor_line, clean_pos_list))\n",
    "    candidates.append(match_NA(mor_line, clean_pos_list))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a54419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_particles = [\"yes\",\"no\",\"yeah\",\"yup\",\"yip\",\"nah\"]\n",
    "punc = [\".\",\"?\",\"!\"]\n",
    "def match_frp(clean_line):\n",
    "    for item in punc:\n",
    "        if item in clean_line:\n",
    "            clean_line = clean_line.strip(item)\n",
    "            clean_line = clean_line.strip()\n",
    "    if clean_line in response_particles:\n",
    "        return(\"frp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "formulaic_interjections = [\"ok\", \"okay\", \"okey dokey\", \"okey\", \"please\", \"thank you\", \"thanks\", \"hello\", \"hi\", \"hiya\", \"goodbye\", \"good bye\", \"bye\", \"byebye\", \"bye-bye\", \"bye bye\"]\n",
    "punc = [\".\",\"?\",\"!\"]\n",
    "def match_ffi(clean_line):    \n",
    "    for item in punc:\n",
    "        if item in clean_line:\n",
    "            clean_line = clean_line.strip(item)\n",
    "            clean_line = clean_line.strip()\n",
    "    if clean_line in formulaic_interjections:\n",
    "        return(\"ffi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fow(line, clean_pos_list):\n",
    "    if line.count(\"|\") == 1:\n",
    "        return(\"fow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fnp(line, clean_pos_list):\n",
    "    np_count = line.count(\"n|\") + line.count(\"n:prop|\") + line.count(\"pro:per|\") + line.count(\"pro:indef|\") + line.count(\"n:let\") + line.count(\"on|\")\n",
    "    if np_count > 0:\n",
    "        return(\"fnp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119daa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fvp(line, clean_pos_list):\n",
    "    v_count = line.count(\"v|\") + line.count(\"aux|\") + line.count(\"cop|\") + line.count(\"mod|\") - line.count(\"adv|\")\n",
    "    if v_count > 0:\n",
    "        return(\"fvp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fpp(line, clean_pos_list):\n",
    "    if line.count(\"prep|\") > 0:\n",
    "        return(\"fpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fom(line, clean_pos_list):\n",
    "    if len(clean_pos_list) > 1:\n",
    "        return(\"fom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_qwh(line, clean_pos_list):\n",
    "    x = re.findall(\"((co)(\\|\\w*|\\|\\w*)( |\\~))*(pro:int|det:int|pro:rel|conj)(\\|\\w*|\\|\\w*)( |\\~)((n|adj|pro:per)(\\|\\w*|\\|\\w*)( |\\~))*(mod|aux|cop|v)(\\|\\w*|\\|\\w*)\", line)\n",
    "    if x:\n",
    "        if clean_pos_list[0] not in [\"mod\",\"aux\",\"cop\"]:\n",
    "            return(\"qwh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_qyn(line, clean_pos_list):\n",
    "    if clean_pos_list[0] not in [\"pro:int\",\"det:int\",\"pro:rel\"]:\n",
    "        return(\"qyn\")\n",
    "    else:\n",
    "        return(\"qwh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_imp(line, clean_pos_list):\n",
    "    x = re.findall(\"(v|mod)(\\|\\w*|\\|\\w*)(\\&\\w*)*( |\\~)((qn)(\\|\\w*|\\|\\w*)( |\\~))*(adve|pro:\\d*|prep|det|dia)\", line)\n",
    "    if x:\n",
    "        return(\"imp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aed3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_cop(line, clean_pos_list):\n",
    "    num_v = line.count(\"v|\")\n",
    "    num_adv = line.count(\"adv|\")\n",
    "    num_v = num_v - num_adv\n",
    "    num_be = line.count(\"cop|be\")\n",
    "    if num_be >= 1 and num_v < 1:\n",
    "        if line[0:4] != \"cop|\":\n",
    "            return(\"cop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf5e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_spt(line, clean_pos_list):\n",
    "    joined_pos = ' '.join(clean_pos_list)\n",
    "    #print(joined_pos)\n",
    "    x = re.findall(\"(pro:per|pro:sub|n|pro:int|n:prop|det:dem) (.)*(v|mod|aux|co) (.)*(pro:per|pro:obj|n |pro:dem|dia|pro:sub|n:prop|pro:indef|pro:refl)\", joined_pos)\n",
    "    if x:\n",
    "        if line[0:2] != \"v|\":\n",
    "            return(\"spt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_spi(line, clean_pos_list):\n",
    "    x = re.findall(\"(pro:per|pro:sub|n|pro:int|n:prop|det:dem)(\\|\\w*|\\|\\w*)(\\&\\w*)*( |\\~)(v|cop|mod|aux)(\\|\\w*|\\|\\w*)(\\&\\w*)*( |\\~)\", line)\n",
    "    if x:\n",
    "        if line[0:2] != \"v|\":\n",
    "            return(\"spi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_spo(line, clean_pos_list):\n",
    "    if True == True:\n",
    "        return(\"spo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_com(line, clean_pos_list):\n",
    "    num_v = line.count(\"v|\")\n",
    "    num_adv = line.count(\"adv|\")\n",
    "    num_v = num_v - num_adv\n",
    "    num_part = line.count(\"part|\")\n",
    "    num_v = num_v + num_part\n",
    "    if num_v > 1:\n",
    "        return(\"com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_com2(line, clean_pos_list):\n",
    "    x = re.findall(\"(pro:per|pro:obj|n |pro:dem|dia|pro:sub|n:prop|pro:indef|pro:refl)(\\|\\w*|\\|\\w*)(\\&\\w*)*( |\\~)(v|mod|aux)(\\|\\w*|\\|\\w*)(\\&\\w*)*( |\\~)\", line)\n",
    "    if len(x) > 1:\n",
    "        return(\"com\")\n",
    "    else:\n",
    "        num_v = line.count(\"v|\")\n",
    "        num_adv = line.count(\"adv|\")\n",
    "        num_v = num_v - num_adv\n",
    "        num_part = line.count(\"part|\")\n",
    "        num_v = num_v + num_part\n",
    "        if num_v > 2:\n",
    "            return(\"com\") \n",
    "    y = re.findall(\"(conj\\|if|comp|if) (pro:dem|pro:per|pro:sub)\", line)\n",
    "    if y:\n",
    "        return(\"com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_NA(line, clean_pos_list):\n",
    "    if True == True:\n",
    "        return(\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf54d3b",
   "metadata": {},
   "source": [
    "## Add CXNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64991d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cxns(dataframe):\n",
    "    parses = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if row['speaker'] != 'CHI':\n",
    "            parse = find_cxn(row['mor_utterance'], row['clean_utterance'])\n",
    "            parses.append(parse)\n",
    "        else:\n",
    "            parses.append(\"NA\")\n",
    "    return parses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b55f15",
   "metadata": {},
   "source": [
    "### Test rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85994cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cxns(dataframe):\n",
    "    count = 0\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    parses = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if row['speaker'] != 'CHI':\n",
    "            count = count + 1\n",
    "            anno = row['cxn_manual']\n",
    "            parse = find_cxn(row['mor_utterance'], row['clean_utterance'])\n",
    "            parses.append(parse)\n",
    "            if anno == parse:\n",
    "                right = right + 1\n",
    "                #print(row['clean_utterance'])\n",
    "                #print(\"Manual anno: \" + anno)\n",
    "                #print(parse)\n",
    "            else:\n",
    "                wrong = wrong + 1\n",
    "                if anno and parse != None:\n",
    "                    print(row['clean_utterance'])\n",
    "                    print(\"Manual anno: \" + anno)\n",
    "                    print(parse)\n",
    "        else:\n",
    "            parses.append(\"NA\")\n",
    "    print(\"For \"+str(count)+\" sentences, \"+str(right)+ \" were parsed correctly, and \"+str(wrong)+\" not.\")\n",
    "    rate = 100 / count * right\n",
    "    print(\"Match rate: \"+str(rate))\n",
    "    return parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97314c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_parses = eval_cxns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cxn_parsed\"] = my_parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a917e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"parse_anno.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5487c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cxns_debug(dataframe):\n",
    "    count = 0\n",
    "    right = 0\n",
    "    wrong = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        if row['speaker'] != 'CHI':\n",
    "            count = count + 1\n",
    "            anno = row['cxn_manual']\n",
    "            parse = find_cxn_debug(row['mor_utterance'], row['clean_utterance'])\n",
    "            if anno in parse:\n",
    "                right = right + 1\n",
    "                #print(row['clean_utterance'])\n",
    "                #print(\"Manual anno: \" + anno)\n",
    "                #print(parse)\n",
    "            else:\n",
    "                wrong = wrong + 1\n",
    "                if anno and parse != None:\n",
    "                    print(row['clean_utterance'])\n",
    "                    print(\"Manual anno: \" + anno)\n",
    "                    print(parse)\n",
    "    print(\"For \"+str(count)+\" sentences, \"+str(right)+ \" were parsed correctly, and \"+str(wrong)+\" not.\")\n",
    "    rate = 100 / count * right\n",
    "    print(\"Match rate: \"+str(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e16d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cxns_debug(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b615c1",
   "metadata": {},
   "source": [
    "# Full parsing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for dirpath, dirnames, filenames in os.walk(\"C:/Users/User/Desktop/converted_temp/\"):\n",
    "    for filename in [f for f in filenames if f.endswith(\".csv\")]:\n",
    "        file_list.append(os.path.join(dirpath, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    anno_dataframe = pd.read_csv(file, sep=\"\\t\", index_col=0, na_filter = False)\n",
    "    parses = add_cxns(anno_dataframe)\n",
    "    anno_dataframe[\"cxn_parsed\"] = parses\n",
    "    file_name = file.split(\"/\")\n",
    "    file_name = file_name[-1]\n",
    "    output_file_name = file_name.split(\".\")\n",
    "    output_file_name = output_file_name[0]\n",
    "    output_file_name = output_file_name + \"-annotated.csv\"\n",
    "    anno_dataframe.to_csv(\"C:/Users/User/Desktop/converted_temp/annotated/\"+output_file_name, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a306fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
